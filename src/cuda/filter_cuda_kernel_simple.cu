#import <stdlib.h>
#include <stdio.h>
#include <assert.h>

#include "cuda_test.h"

#define MAX_RANGE 20000 // meters
#define MAX_VEL 15 // meters per second

#define DEVICE_PI acosf(-1)

// linear congruential random number generator constants
// these values are used in java.util.Random.next()
#define a 0x5DEECE66DL
#define c 0xB
#define mask_bits 48
// generate only 31 bits so that we always generate positive integers
#define result_bits 31

// bit mask the least significant m bits
const long mask = ( 1L << mask_bits ) - 1;

const int LCG_RAND_MAX = ( 1 << result_bits ) - 1;

// implementation based on examples from:
// http://en.wikipedia.org/wiki/Linear_congruential_generator
// java.util.Random.next()
__device__ int device_lcg_rand( int x )
{
  // bitwise and with mask is equivalent to mod 2^mask_bits
  long xl = (x * a + c) & mask;
  // we have generated mask_bits but only need result_bits
  // use the highest order bits because they have longer periods
  return (int) ( xl >> ( mask_bits - result_bits ) );
}

// Return a random float value evenly distributed between 0 and max
// Because cuda threads will keep track of their own seeds, this function
// and the others like it are not random. They simply take an already
// generated random value (seed) and transform it in some way.
// Seed values should be generated by repeated calls to device_lcg_rand().
__device__ float device_frand0( int seed, float max )
{
  return ( float ) seed / ( float ) RAND_MAX * max ;
}

// return a random float value evenly distributed between min and max
__device__ float device_frand( int seed, float min, float max )
{
  float diff = max - min;
  return device_frand0( seed, diff ) + min;
}


void checkCUDAError(const char *msg)
{
    cudaError_t err = cudaGetLastError();
    if( cudaSuccess != err) 
    {
        fprintf(stderr, "Cuda error: %s: %s.\n", msg, cudaGetErrorString( err) );
        exit(-1);
    }
    else
    {
        fprintf(stderr, "No error: %s.\n", msg);
    }
}


__global__ void test_particles_kernel( struct particles *list )
{
  int index = blockIdx.x * blockDim.x + threadIdx.x;
  (list+index)->x_pos = blockIdx.x;
  (list+index)->y_pos = blockDim.x;
  (list+index)->x_vel = threadIdx.x;
  (list+index)->y_vel = index;
  (list+index)->weight = 20.0;
}

// CUDA kernel function : initialize a particle
__global__ void init_particles_kernel( struct particles *list )
{
  int index = blockIdx.x * blockDim.x + threadIdx.x;

  int seed = list[index].seed;

  list[index].x_pos  = device_frand( seed, -MAX_RANGE, MAX_RANGE );
  seed = device_lcg_rand( seed );
  list[index].y_pos  = device_frand( seed, -MAX_RANGE, MAX_RANGE );
  seed = device_lcg_rand( seed );
  list[index].x_vel  = device_frand( seed, -MAX_VEL, MAX_VEL );
  seed = device_lcg_rand( seed );
  list[index].y_vel  = device_frand( seed, -MAX_VEL, MAX_VEL );
  seed = device_lcg_rand( seed );
  list[index].weight = 1.0;

  list[index].seed = seed;
}

extern "C" void init_particles( struct particles *host, int num )
{
  int numThreadsPerBlock = 32;
  int numBlocks = num / numThreadsPerBlock;

  // launch kernel
  dim3 dimGrid(numBlocks);
  dim3 dimBlock(numThreadsPerBlock);
  init_particles_kernel<<< dimGrid, dimBlock >>>( host );

  // block until the device has completed kernel execution
  cudaThreadSynchronize();

  // check if the init_particle_val kernel generated errors
  checkCUDAError("init_particle_val");
}

extern "C" void test_particles( struct particles *host, int num )
{
  int numThreadsPerBlock = 32;
  int numBlocks = num / numThreadsPerBlock;

  // launch kernel
  //dim3 dimGrid(numBlocks);
  //dim3 dimBlock(numThreadsPerBlock);
  dim3 dimGrid(16);
  dim3 dimBlock(2);
  test_particles_kernel<<< dimGrid, dimBlock >>>( host );

  // block until the device has completed kernel execution
  cudaThreadSynchronize();

  // check if the init_particle_val kernel generated errors
  checkCUDAError("init_particle_val");
}

extern "C" void h_init_seed( struct particles *host, int num )
{
  int i;

  for ( i = 0 ; i < num ; i++ )
  {
    host[i].seed = rand();
  }
}

extern "C" void copy_particles_host_to_device( struct particles *device, struct particles *host, int num )
{
  int size = sizeof( struct particles ) * num;

  cudaMemcpy( device, host, size, cudaMemcpyHostToDevice );
}

extern "C" void copy_particles_device_to_host( struct particles *host, struct particles *device, int num )
{
  int size = sizeof( struct particles ) * num;

  cudaMemcpy( host, device, size, cudaMemcpyDeviceToHost );
}

// allocate memory for num particles on device
extern "C" struct particles *d_init_particle_mem( int num )
{
  int size = sizeof( struct particles ) * num ;
  struct particles *list;

  cudaMalloc( (void **) &list, size );

  return list;
}

// free particle memory on host
extern "C" void h_free_particle_mem( struct particles *list )
{
  free( list );
}

// free particle memory on device
extern "C" void d_free_particle_mem( struct particles *list )
{
  cudaFree( list );
}






